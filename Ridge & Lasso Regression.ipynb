{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdfc2125",
   "metadata": {},
   "source": [
    "# Linear Regression vs Ridge vs Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84d3446",
   "metadata": {},
   "source": [
    "For this notebook, we'll use the Cereals.csv dataset available in the datasets folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e19ec4f",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebe0bcd",
   "metadata": {},
   "source": [
    "Import Libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa5f702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92e7dfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cereals.CSV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58177b51",
   "metadata": {},
   "source": [
    "Selecting the target and the predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e0f3935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Manuf', 'Type', 'Calories', 'Protein', 'Fat', 'Sodium',\n",
       "       'Fiber', 'Carbo', 'Sugars', 'Potass', 'Vitamins', 'Shelf', 'Weight',\n",
       "       'Cups', 'Rating', 'Cold', 'Nabisco', 'Quaker', 'Kelloggs',\n",
       "       'GeneralMills', 'Ralston', 'AHFP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abd13eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,3:8] #Predictors - Calories, Protein, Fat, Sodium, Fiber\n",
    "y = df['Rating'] #Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee9c2ae",
   "metadata": {},
   "source": [
    "Standardize the predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "defb15f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "scaled_X = pd.DataFrame(scaled_X, columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b100d8a7",
   "metadata": {},
   "source": [
    "Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4a9e904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size = 0.33, random_state = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e044d3",
   "metadata": {},
   "source": [
    "Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2e9401f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.87173411,  5.02729917, -4.07821314, -2.94667722,  3.37461453])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = LinearRegression()\n",
    "model = lm.fit(X_train,y_train)\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4390bbb3",
   "metadata": {},
   "source": [
    "Prediction from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa40d06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb118f90",
   "metadata": {},
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15dd0af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "lm_mse = mean_squared_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2988ca7d",
   "metadata": {},
   "source": [
    "Prediction from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a4cd665",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "032d3fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.491113847957383"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf4f84e",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1d543f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6190a3",
   "metadata": {},
   "source": [
    "Regression with no penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f539f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge1 = Ridge(alpha=0) # penalty is set to 0, in other words no penalty\n",
    "model1 = ridge1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89629fa",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d512214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred1 = model1.predict(X_test) #test set\n",
    "ridge_mse = mean_squared_error(y_test, y_test_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061703a7",
   "metadata": {},
   "source": [
    "Regression with penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "138c2121",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge2 = Ridge(alpha=1)\n",
    "model2 = ridge2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe1aa0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.82339932,  4.91201241, -3.98539246, -2.89120078,  3.37984124])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62340a2",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b335f1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1ba20df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_penalty_mse = mean_squared_error(y_test, y_test_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4fc494a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Ridge with no penalty  39.723787963685815\n",
      "MSE Ridge with penalty  40.12287359221361\n"
     ]
    }
   ],
   "source": [
    "print('MSE Ridge with no penalty'+ ' ',ridge_mse)\n",
    "print('MSE Ridge with penalty'+ ' ',ridge_penalty_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bbe36d",
   "metadata": {},
   "source": [
    "The MSE is better with no penalty. Let's check with other penalty value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a41441c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha =  1  / MSE = 40.12287359221361\n",
      "Alpha =  2  / MSE = 40.56640387907688\n",
      "Alpha =  3  / MSE = 41.048428768138834\n",
      "Alpha =  4  / MSE = 41.563895409467236\n",
      "Alpha =  5  / MSE = 42.10847913329299\n",
      "Alpha =  6  / MSE = 42.67845279264998\n",
      "Alpha =  7  / MSE = 43.27058435490195\n",
      "Alpha =  8  / MSE = 43.882055642962186\n",
      "Alpha =  9  / MSE = 44.51039714760829\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,10):\n",
    "    ridge3 = Ridge(alpha=i)\n",
    "    model3 = ridge3.fit(X_train,y_train)\n",
    "    y_test_pred3 = model3.predict(X_test)\n",
    "    print('Alpha = ',i,' / MSE =',mean_squared_error(y_test, y_test_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0c3fcd",
   "metadata": {},
   "source": [
    "MSE keeps on increasing with the penalty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a091b5",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45105803",
   "metadata": {},
   "source": [
    "We're using the same process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75f64531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso1 = Lasso(alpha=1)\n",
    "model4 = lasso1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfbbc59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred4 = model4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b787000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso MSE  53.230755966755275\n"
     ]
    }
   ],
   "source": [
    "lasso_mse = mean_squared_error(y_test, y_test_pred4)\n",
    "print('Lasso MSE'+' ',lasso_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "558660d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.21048538,  3.97280159, -2.36889073, -1.6173548 ,  2.84854426])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f67c207d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha =  1  / MSE = 53.230755966755275\n",
      "Alpha =  2  / MSE = 81.19659961380344\n",
      "Alpha =  3  / MSE = 102.08519715487013\n",
      "Alpha =  4  / MSE = 118.42300565357677\n",
      "Alpha =  5  / MSE = 137.7503644675328\n",
      "Alpha =  6  / MSE = 152.03337767219023\n",
      "Alpha =  7  / MSE = 165.00463287678195\n",
      "Alpha =  8  / MSE = 178.96647591930483\n",
      "Alpha =  9  / MSE = 188.29382147859874\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,10):\n",
    "    lasso3 = Lasso(alpha=i)\n",
    "    model5 = lasso3.fit(X_train,y_train)\n",
    "    y_test_pred5 = model5.predict(X_test)\n",
    "    print('Alpha = ',i,' / MSE =',mean_squared_error(y_test, y_test_pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4ee04e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
